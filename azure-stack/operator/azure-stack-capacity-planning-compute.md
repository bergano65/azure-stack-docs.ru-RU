---
title: Планирование вычислительной емкости в Azure Stack | Документация Майкрософт
description: Сведения о планировании емкости для развертываний Azure Stack.
services: azure-stack
documentationcenter: ''
author: prchint
manager: femila
editor: ''
ms.assetid: ''
ms.service: azure-stack
ms.workload: na
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/31/2019
ms.author: justinha
ms.reviewer: prchint
ms.lastreviewed: 05/31/2019
ms.openlocfilehash: e549413798ffc3c06c95bfbcf50ab4929ffeaf63
ms.sourcegitcommit: 80775f5c5235147ae730dfc7e896675a9a79cdbe
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/03/2019
ms.locfileid: "66461097"
---
# <a name="azure-stack-compute"></a>Службы вычислений Azure Stack

В Azure Stack поддерживаются разные [размеры виртуальных машин](https://docs.microsoft.com/azure-stack/user/azure-stack-vm-sizes). В Azure используется несколько методов ограничения ресурсов. Это предотвращает их чрезмерное использование (на уровне локальных серверов и служб). Если не ограничить потребление ресурсов клиентом, его работа может ухудшиться при чрезмерном использовании ресурсов другими клиентами. Для исходящего трафика виртуальной машины в Azure Stack предусмотрены ограничения пропускной способности, соответствующие ограничениям в Azure. Для ресурсов хранилища в Azure Stack предусмотрены ограничения числа операций ввода-вывода в секунду. Это предотвращает чрезмерное использование ресурсов клиентами при доступе к хранилищу.

>[!IMPORTANT]
>[Планировщик ресурсов Azure Stack](https://aka.ms/azstackcapacityplanner) не предполагает и не обеспечивает определенную производительность операций ввода-вывода.

## <a name="vm-placement"></a>Размещение виртуальной машины

В Azure Stack размещение виртуальной машины клиента выполняется автоматически модулем размещения на доступных узлах. При размещении виртуальных машин следует учитывать два момента: достаточный ли объем памяти на узле для этого типа виртуальной машины и входят ли виртуальные машины в [группу доступности](https://docs.microsoft.com/azure/virtual-machines/windows/manage-availability) или [масштабируемые наборы виртуальных машин](https://docs.microsoft.com/azure/virtual-machine-scale-sets/overview).  

Чтобы добиться высокого уровня доступности рабочих систем с несколькими виртуальными машинами в Azure Stack, эти виртуальные машины размещаются в группе доступности, которая распределяет их между несколькими доменами сбоя. Домен сбоя в группе доступности определяется как отдельный узел в единице масштабирования. Azure Stack поддерживает группы доступности с максимально тремя доменами сбоя, что гарантирует согласованность с Azure. Виртуальные машины, размещенные в группе доступности, физически изолируются друг от друга и максимально равномерно распределяются между несколькими доменами сбоя (узлами Azure Stack). В случае сбоя оборудования виртуальные машины из поврежденного домена сбоя перезагружаются в других доменах сбоя, но, если это возможно, остаются в доменах сбоя, отдельных от других виртуальных машин в той же группе доступности. Когда работоспособность узла восстанавливается, виртуальные машины перераспределяются, что обеспечивает высокий уровень доступности.  

Масштабируемые наборы виртуальных машин используют группы доступности в серверной части, чтобы каждый экземпляр масштабируемого набора виртуальных машин размещался в домене сбоя. Это означает, что они используют отдельные узлы инфраструктуры Azure Stack. Например, в системе Azure Stack, состоящей из четырех узлов, создание масштабируемого набора виртуальных машин, состоящего из трех экземпляров, может завершиться сбоем из-за того, что емкости четырех узлов будет недостаточно для размещения трех экземпляров масштабируемого набора виртуальных машин на трех отдельных узлах Azure Stack. Кроме того, узлы Azure Stack можно заполнять на разных уровнях до попытки размещения. 

Azure Stack не предполагает интенсивное использование памяти. При этом допускается интенсивное использование определенного числа физических ядер. Так как алгоритмы подготовки не учитывают избыточную подготовку виртуальных ядер относительно физических, это отношение в каждом узле может быть разным. Майкрософт не предоставляет рекомендации по соотношению физических и виртуальных ядер из-за отличающихся рабочих нагрузок и требований к уровню обслуживания. 

## <a name="azure-stack-memory"></a>Память Azure Stack 

В Azure Stack работают виртуальные машины, которые были успешно подготовлены. Например, если узел находится в автономном режиме из-за сбоя оборудования, Azure Stack попытается перезапустить эту виртуальную машину на другом узле. Второй пример — установка исправлений и обновлений программного обеспечения Azure Stack. Если нужно перезагрузить физический узел, будет предпринята попытка переместить виртуальные машины, работающие на этом узле, на другой узел, доступный в решении.   

Такое управление виртуальными машинами или их перемещение возможно только при наличии зарезервированного объема памяти для перезапуска или миграции. Часть всей памяти узла резервируется и становится недоступной для размещения виртуальной машины клиента. 

Вы можете просмотреть круговую диаграмму на портале администрирования, чтобы оценить неиспользуемую и используемую в Azure Stack память. На схеме ниже показан объем физической памяти в единице масштабирования Azure Stack в Azure Stack:

![Объем физической памяти](media/azure-stack-capacity-planning/physical-memory-capacity.png)

Используемая память состоит из нескольких компонентов. Следующие компоненты используют память в соответствующем разделе круговой диаграммы.  

- Резервирование или использование ОС узла — это объем памяти, используемый операционной системой (ОС) узла, таблицами страниц виртуальной памяти, процессами в ОС узла, а также кэшем памяти локальных дисковых пространств. 
- Службы инфраструктуры — это инфраструктура виртуальных машин, работающих в Azure Stack. В выпуске Azure Stack 1902 предусмотрена 31 виртуальная машина. Все они потребляют 242 ГБ + (4 ГБ x число узлов). Внутренняя структура служб позволяет вводить в будущем новые службы инфраструктуры по мере их разработки.
- Резерв для устойчивости — Azure Stack резервирует часть памяти для обеспечения доступности клиента во время сбоя одного узла, а также во время установки исправлений и обновлений для обеспечения успешной динамической миграции виртуальных машин. 
- Виртуальные машины клиента — это клиентские виртуальные машины, созданные пользователями Azure Stack. Наряду с работающими виртуальными машинами память также потребляют виртуальные машины, которые работают в структуре. Это означает, что виртуальные машины, которые находятся в состоянии **Создание** или **Сбой**, либо работа которых завершена из гостевой ОС, также будут потреблять памяти. При этом виртуальные машины, которые были освобождены путем остановки, не потребляют память Azure Stack. 

Лучший способ оценить потребление памяти на портале — воспользоваться [планировщиком ресурсов Azure Stack](https://aka.ms/azstackcapacityplanner), чтобы просмотреть влияние разных рабочих нагрузок. Следующие вычисления соответствуют расчетам планировщика.

Это вычисление позволяет рассчитать общий объем доступной памяти для размещения виртуальных машин клиента. Этот объем памяти предназначен для всей единицы масштабирования Azure Stack. 


  Доступный объем памяти для размещения виртуальных машин = общий объем памяти на узле - резерв для устойчивости - объем памяти, используемый работающими виртуальными машинами клиента - служебные данные инфраструктуры Azure Stack <sup>1</sup>

  Резерв устойчивости = H + R * ((N-1) * H) + V * (N-2)

> Описание
> - H = размер памяти на одном сервере
> - N = размер единицы масштабирования (число серверов)
> - R = резерв для нагрузки ОС, который составляет 0,15 в этой формуле <sup>2</sup>
> - V = самая большая виртуальная машина в единице масштабирования

  <sup>1</sup> Служебные данные инфраструктуры Azure Stack: 242 ГБ + (4 ГБ x число узлов). Для размещения инфраструктуры Azure Stack используется приблизительно 31 виртуальная машина. Все они в совокупности потребляют примерно 242 ГБ памяти (4 ГБ х число узлов) и имеют 146 виртуальных ядер. Такое количество виртуальных машин обосновывается необходимостью в разделении служб с целью удовлетворить требования к безопасности, масштабируемости, обслуживанию и применению исправлений. Внутренняя структура служб позволяет вводить в будущем новые службы инфраструктуры по мере их разработки. 

  <sup>2</sup> Резерв для нагрузки ОС составляет 15 % (0,15) памяти узла. Значение резерва операционной системы является приблизительным и зависит от объема физической памяти на сервере и общих накладных расходов операционной системы.


Значение V (самая большая виртуальная машина в единице масштабирования) меняется динамически в зависимости от максимального размера памяти виртуальной машины в клиенте. Например, оно может быть равно 7 ГБ, 112 ГБ или соответствовать другому размеру памяти виртуальной машины, поддерживаемому решением Azure Stack. Изменение самой большой виртуальной машины в структуре Azure Stack приведет к увеличению резерва для устойчивости, а также увеличению объема памяти самой виртуальной машины. 

> [!NOTE]
> Требования к планированию ресурсов для сетевого взаимодействия минимальны, так как настраивается только размер общедоступного виртуального IP-адреса. См. подробнее о [добавлении дополнительных общедоступных IP-адресов уровня экземпляра в Azure Stack](azure-stack-add-ips.md).

## <a name="next-steps"></a>Дополнительная информация
См. подробнее о [хранилище Azure Stack](azure-stack-capacity-planning-storage.md).